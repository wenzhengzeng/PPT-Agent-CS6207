["code_run_correct", "replace_paragraph(0, 0, \"Language Model Reasoning\")", null]
["code_run_correct", "replace_paragraph(1, 0, \"Introduction to Recent Developments and Challenges\")", null]
["code_run_correct", "replace_paragraph(1, 1, \"Unknown\")", null]
["code_run_correct", "replace_paragraph(0, 0, \"Key Contributions\")", null]
["code_run_correct", "replace_paragraph(1, 0, \"Highlighting Innovations\")", null]
["code_run_correct", "replace_paragraph(1, 1, \"Revolutionizing LLMs through direct RL application to base models skips initial SFT, fostering complex CoT exploration.\")", null]
["code_run_correct", "replace_paragraph(1, 2, \"DeepSeek-R1-Zero showcases novel long CoTs via RL-only validation, enhancing LLM reasoning capabilities dramatically.\")", null]
["code_run_correct", "replace_paragraph(1, 3, \"DeepSeek-R1 pipeline melds RL and dual SFT stages for reasoning pattern growth, providing significant industrial advantages.\")", null]
["code_run_correct", "replace_paragraph(1, 4, \"Distilling larger model reasoning into smaller models enables remarkable benchmark performance, with superior reasoning capabilities.\")", null]
["code_run_correct", "replace_paragraph(0, 0, \"Evaluation and Conclusion\")", null]
["code_run_correct", "replace_paragraph(1, 0, \"DeepSeek-R1 excels with a 79.8% Pass@1 on AIME 2024, slightly surpassing OpenAI-o1-1217. In MATH-500, it hits top-tier performance with 97.3%.\")", null]
["code_run_correct", "replace_paragraph(1, 1, \"In coding tasks, it achieves expert-level ratings, outperforming 96.3% of humans on competitive platforms. Engineering tasks show improvements over DeepSeek-V3.\")", null]
["code_run_correct", "replace_paragraph(1, 2, \"On knowledge benchmarks like MMLU and GPQA Diamond, DeepSeek-R1 outpaces DeepSeek-V3 and rivals OpenAI-o1-1217 in factual inquiries.\")", null]
["code_run_correct", "replace_paragraph(1, 3, \"Overall, DeepSeek-R1 demonstrates substantial advancements, with particular strengths in reasoning and knowledge-based tasks.\")", null]
